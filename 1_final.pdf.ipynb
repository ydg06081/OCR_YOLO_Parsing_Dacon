{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DACON 재정정보 AI 검색 알고리즘 경진대회\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1. 라이브러리 설치 및 라이브러리 Import\n",
    "데이터 처리를 위해 필요한 라이브러리를 불러오고 기본 설정을 하는 셀입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "git is already the newest version (1:2.25.1-1ubuntu3.13).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "poppler-utils is already the newest version (0.86.1-0ubuntu1.4).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 47 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "!apt-get install git -y\n",
    "!apt-get install poppler-utils -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pdf2image\n",
      "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: pillow in /root/.conda/lib/python3.10/site-packages (from pdf2image) (10.4.0)\n",
      "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
      "Installing collected packages: pdf2image\n",
      "Successfully installed pdf2image-1.17.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/THU-MIG/yolov10.git\n",
    "!pip install -q supervision\n",
    "!pip install pdf2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/moured/YOLOv10-Document-Layout-Analysis/releases/download/doclaynet_weights/yolov10x_best.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymupdf\n",
      "  Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
      "Collecting PyMuPDFb==1.24.9 (from pymupdf)\n",
      "  Downloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.4 kB)\n",
      "Downloading PyMuPDF-1.24.9-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading PyMuPDFb-1.24.9-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: PyMuPDFb, pymupdf\n",
      "Successfully installed PyMuPDFb-1.24.9 pymupdf-1.24.9\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting natsort\n",
      "  Downloading natsort-8.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading natsort-8.4.0-py3-none-any.whl (38 kB)\n",
      "Installing collected packages: natsort\n",
      "Successfully installed natsort-8.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pymupdf4llm\n",
      "  Downloading pymupdf4llm-0.0.12-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: pymupdf>=1.24.2 in /root/.conda/lib/python3.10/site-packages (from pymupdf4llm) (1.24.9)\n",
      "Requirement already satisfied: PyMuPDFb==1.24.9 in /root/.conda/lib/python3.10/site-packages (from pymupdf>=1.24.2->pymupdf4llm) (1.24.9)\n",
      "Downloading pymupdf4llm-0.0.12-py3-none-any.whl (22 kB)\n",
      "Installing collected packages: pymupdf4llm\n",
      "Successfully installed pymupdf4llm-0.0.12\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pymupdf\n",
    "!pip install natsort\n",
    "!pip install pymupdf4llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.42.3\n",
      "  Downloading transformers-4.42.3-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from transformers==4.42.3) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from transformers==4.42.3) (0.24.6)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from transformers==4.42.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from transformers==4.42.3) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from transformers==4.42.3) (6.0.1)\n",
      "Collecting regex!=2019.12.17 (from transformers==4.42.3)\n",
      "  Downloading regex-2024.7.24-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from transformers==4.42.3) (2.32.3)\n",
      "Collecting safetensors>=0.4.1 (from transformers==4.42.3)\n",
      "  Downloading safetensors-0.4.4-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tokenizers<0.20,>=0.19 (from transformers==4.42.3)\n",
      "  Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from transformers==4.42.3) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.3) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.42.3) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from tqdm>=4.27->transformers==4.42.3) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from requests->transformers==4.42.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from requests->transformers==4.42.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from requests->transformers==4.42.3) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from requests->transformers==4.42.3) (2024.7.4)\n",
      "Downloading transformers-4.42.3-py3-none-any.whl (9.3 MB)\n",
      "   ---------------------------------------- 0.0/9.3 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 6.0/9.3 MB 28.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.3/9.3 MB 30.6 MB/s eta 0:00:00\n",
      "Downloading regex-2024.7.24-cp312-cp312-win_amd64.whl (269 kB)\n",
      "Downloading safetensors-0.4.4-cp312-none-win_amd64.whl (286 kB)\n",
      "Downloading tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 63.0 MB/s eta 0:00:00\n",
      "Installing collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.7.24 safetensors-0.4.4 tokenizers-0.19.1 transformers-4.42.3\n",
      "Requirement already satisfied: torch in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ydg06\\anaconda3\\envs\\yolo\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.42.3\n",
    "!pip install --upgrade torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install accelerate\n",
    "!pip install -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install transformers[torch] -U\n",
    "!pip install --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import supervision as sv\n",
    "import os\n",
    "import cv2\n",
    "import supervision as sv\n",
    "from ultralytics import YOLO\n",
    "import fitz\n",
    "from natsort import natsorted\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import pymupdf4llm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  2.함수 선언"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDF 파일을 PNG 이미지로 변환하여 저장\n",
    "- PDF 크기를 유지한 채 이미지로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:37<00:00,  4.21s/it]\n"
     ]
    }
   ],
   "source": [
    "def convert_pdf_to_png(pdf_path, output_dir):\n",
    "    \"\"\"PDF 파일을 PNG 이미지로 변환하여 저장\"\"\"\n",
    "    pages = convert_from_path(pdf_path, dpi=300)  # dpi 설정으로 해상도 조절 가능\n",
    "    for i, page in enumerate(pages):\n",
    "        # 페이지 크기 가져오기 (포인트 단위)\n",
    "        page_width = int(page.width * 0.352778)  # 포인트를 픽셀로 변환 (72dpi 기준)\n",
    "        page_height = int(page.height * 0.352778)  # 포인트를 픽셀로 변환 (72dpi 기준)\n",
    "\n",
    "        # 이미지 변환 (PDF 크기 유지)\n",
    "        image = convert_from_path(\n",
    "                pdf_path, \n",
    "                dpi=300, \n",
    "                first_page=i+1, \n",
    "                last_page=i+1,\n",
    "                size=(page_width, page_height)  # 이미지 크기를 PDF 페이지 크기로 설정\n",
    "        )[0]\n",
    "\n",
    "        image.save(os.path.join(output_dir, f\"page_{i+1}.png\"), \"PNG\")\n",
    "\n",
    "\n",
    "folder_path = './test_source' \n",
    "pdf_name = os.listdir(folder_path)\n",
    "files_name = [f.replace('.pdf', '') for f in os.listdir(folder_path)]\n",
    "\n",
    "pdf_path = \"./test_source/\"  # PDF 파일 경로\n",
    "output_dir = \"./dacon/test_png/\"  # 이미지 저장 폴더 경로\n",
    "for i in tqdm(range(len(pdf_name))):\n",
    "        os.makedirs(output_dir+files_name[i], exist_ok=True)\n",
    "        convert_pdf_to_png(pdf_path+pdf_name[i], output_dir+files_name[i])# 폴더가 없으면 생성\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Yolo모델의 부족한 Detection ablility를 보완합니다.\n",
    "- 글자가 작고 틀이 없는 주석의 특징 때문에 불안정한 Detection을 주석의 특징을 파악하여 파서 텍스트의 문맥 끊김 방지\n",
    "- 중복 된 Detection 객체를 처리 가능\n",
    "- Detection의 좌표를 일정하게 변환하여 안정적으로 파서 가능\n",
    "- 주로 공식 문서 좌측 상단에 있는 머리말을 제거하여 파서 텍스트의 문맥 끊김 방지\n",
    "- 마크다운에서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_number_from_filename(filename):\n",
    "    match = re.search(r'page_(\\d+)', filename)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return 0  \n",
    "    \n",
    "def detect_filter(sorted_detections):\n",
    "    filtered_detections = sorted_detections.copy()  \n",
    "    \n",
    "    \n",
    "    i = 0\n",
    "    while i < len(filtered_detections) - 1:\n",
    "        if np.array_equal(filtered_detections[i]['xyxy'], filtered_detections[i + 1]['xyxy']):\n",
    "            \n",
    "            if filtered_detections[i + 1]['data']['class_name'] == 'Section-header':\n",
    "                filtered_detections.pop(i)\n",
    "            elif filtered_detections[i]['data']['class_name'] == 'Section-header':\n",
    "                filtered_detections.pop(i + 1)\n",
    "            else:\n",
    "                i += 1\n",
    "              \n",
    "        else:\n",
    "            i += 1  \n",
    "\n",
    "    return filtered_detections\n",
    "def width_plus(sorted_detections): \n",
    "                                    \n",
    "    plus_detections = sorted_detections.copy()                                \n",
    "    half = 595.0\n",
    "    foot_count_l = 0\n",
    "    foot_count_r = 0\n",
    "    for plus_detection in plus_detections:\n",
    "        x1,y1,x2,y2 = plus_detection['xyxy']\n",
    "        if plus_detection['data']['class_name'] == 'Section-header':\n",
    "            \n",
    "            if half > x1: # 왼쪽\n",
    "                x2 = 534.12\n",
    "            else: #오른쪽\n",
    "                x2 = 1133.4\n",
    "            new_arr = np.array([x1, y1, x2, y2], dtype=np.float32)\n",
    "            plus_detection['xyxy'] = new_arr\n",
    "            \n",
    "        elif plus_detection['data']['class_name'] == 'Footnote':\n",
    "            if half > x1 and foot_count_l == 0: # 왼쪽\n",
    "                x2 = 534.12\n",
    "                y2 = 780\n",
    "                foot_count_l += 1\n",
    "            elif half < x1 and foot_count_r == 0: #오른쪽\n",
    "                x2 = 1133.4\n",
    "                y2 = 780\n",
    "                foot_count_r += 1\n",
    "            new_arr = np.array([x1, y1, x2, y2], dtype=np.float32)\n",
    "            plus_detection['xyxy'] = new_arr\n",
    "    return  plus_detections\n",
    "vectorizer = TfidfVectorizer()\n",
    "def detect_filter_head(sorted_detections):\n",
    "    filtered_detections = sorted_detections.copy()  \n",
    "    i = 0\n",
    "    \n",
    "    while i < len(filtered_detections) - 1:\n",
    "        x1,y1,x2,y2 = filtered_detections[i]['xyxy']\n",
    "        if y1 <=42.341:\n",
    "            filtered_detections.pop(i)\n",
    "    \n",
    "        else:\n",
    "            i += 1  \n",
    "        \n",
    "    return filtered_detections\n",
    "def trans_table(markdown_tables,table_temp):\n",
    "    max_similarity = 0\n",
    "    table_text = ''\n",
    "    for markdown_table in markdown_tables:\n",
    "        replace_table = markdown_table\n",
    "        cleaned_table = replace_table.replace('|', '').replace('#', '').replace('□', '').replace('-','').replace('\\n','').replace(' ','').replace('*','')\n",
    "        tfidf_matrix = vectorizer.fit_transform([table_temp, cleaned_table])\n",
    "        similarity = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])[0][0]\n",
    "                    \n",
    "        if max_similarity < similarity:\n",
    "                        table_text = markdown_table\n",
    "                        max_similarity = similarity\n",
    "   \n",
    "         \n",
    "    return table_text\n",
    "def transpose_detection(image,new_detections):\n",
    "    image_height, image_width = image.shape[:2]\n",
    "        \n",
    "    if image_height < image_width: \n",
    "            half = image_width / 2\n",
    "            left = []\n",
    "            right = []\n",
    "            \n",
    "            for new_detection in new_detections:\n",
    "                if new_detection['xyxy'][0] < half: \n",
    "                    left.append(new_detection)\n",
    "                else:\n",
    "                    right.append(new_detection)\n",
    "            \n",
    "            \n",
    "            \n",
    "            left_detections = sorted(left, key=lambda x: x['xyxy'][1])\n",
    "            right_detections = sorted(right, key=lambda x: x['xyxy'][1])\n",
    "            sum = left_detections + right_detections\n",
    "            return sum\n",
    "            \n",
    "    else:\n",
    "            return sorted(new_detections, key=lambda x: x['xyxy'][1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM함수 선언\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 10/10 [00:05<00:00,  1.96it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "model_id = \"rtzr/ko-gemma-2-9b-it\"\n",
    "\n",
    "quantization_config_4bit = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quantization_config_4bit,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<end_of_turn>\")\n",
    "]\n",
    "\n",
    "def make_answer(instruction):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": f\"{instruction}\"}\n",
    "    ]\n",
    "\n",
    "    input_ids = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(model.device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=512,\n",
    "        eos_token_id=terminators,\n",
    "        do_sample=True,\n",
    "        temperature=0.9,\n",
    "        top_p=0.9,\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0][input_ids.shape[-1]:], skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.파서함수 선언\n",
    "\n",
    "- 파서함수 상세설명\n",
    "1. Yolo모델을 기반으로 PDF에서 문맥에 맞게 Detection을 함 (과정) PDF -> .png -> Yolo Detection -> Detection 객체\n",
    "2. PyMuPDF,pymupdf4ll를 이용하여 pdf 파일에서 text를 추출\n",
    "3. 일정하지 않은 이미지의 크기를 일정하게 변경\n",
    "4. 이전에 Detection한 객체의 좌표를 이용하여 중복 방지\n",
    "5. 표를 처리하기 위해 pymupdf4ll의 라이브러리를 이용하여 Markdown을 저장하고, Cosine 유사도를 이용하여 처리\n",
    "6. 사람 눈에는 보기 좋지만 컴퓨터에서 순서대로 배치하면 보기 어려운 플로우차트를 LLM을 활용하여 논리적으로 파서\n",
    "7. 너무 짧은 파서 문서는 다음 파서 문서에 병합  \n",
    "8. 함수 실행 시 답답함을 해소하기 위해 진행률을 시각화\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 5 List-items, 2 Pictures, 1 Section-header, 6 Texts, 1 Title, 397.2ms\n",
      "Speed: 0.0ms preprocess, 397.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 13 List-items, 1 Page-footer, 1 Page-header, 8 Section-headers, 1 Table, 3 Texts, 414.8ms\n",
      "Speed: 0.0ms preprocess, 414.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 Footnotes, 20 List-items, 1 Page-footer, 1 Page-header, 3 Section-headers, 1 Table, 3 Texts, 395.9ms\n",
      "Speed: 14.5ms preprocess, 395.9ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Footnote, 11 List-items, 1 Page-header, 7 Section-headers, 3 Tables, 11 Texts, 382.8ms\n",
      "Speed: 2.0ms preprocess, 382.8ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 18 List-items, 1 Page-footer, 6 Section-headers, 3 Tables, 9 Texts, 404.1ms\n",
      "Speed: 0.0ms preprocess, 404.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 8 Footnotes, 20 List-items, 1 Page-footer, 4 Section-headers, 2 Tables, 6 Texts, 403.3ms\n",
      "Speed: 0.0ms preprocess, 403.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Footnotes, 21 List-items, 1 Page-footer, 1 Page-header, 4 Section-headers, 2 Tables, 5 Texts, 389.2ms\n",
      "Speed: 0.0ms preprocess, 389.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 Footnotes, 20 List-items, 1 Page-footer, 1 Page-header, 7 Section-headers, 1 Table, 2 Texts, 433.5ms\n",
      "Speed: 0.0ms preprocess, 433.5ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 1 Page-footer, 1 Page-header, 1 Section-header, 24 Texts, 430.6ms\n",
      "Speed: 0.0ms preprocess, 430.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:11<01:29, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 List-item, 1 Picture, 2 Section-headers, 6 Texts, 1 Title, 401.8ms\n",
      "Speed: 2.9ms preprocess, 401.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 Footnote, 19 List-items, 1 Page-header, 5 Section-headers, 4 Texts, 423.0ms\n",
      "Speed: 10.3ms preprocess, 423.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Caption, 1 Footnote, 13 List-items, 2 Pictures, 3 Section-headers, 7 Texts, 469.6ms\n",
      "Speed: 0.0ms preprocess, 469.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Footnote, 16 List-items, 1 Page-footer, 1 Page-header, 4 Pictures, 7 Section-headers, 9 Texts, 400.8ms\n",
      "Speed: 0.1ms preprocess, 400.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 Footnotes, 21 List-items, 1 Page-footer, 4 Pictures, 6 Section-headers, 13 Texts, 386.1ms\n",
      "Speed: 0.0ms preprocess, 386.1ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Caption, 21 List-items, 2 Page-footers, 4 Pictures, 6 Section-headers, 7 Texts, 466.2ms\n",
      "Speed: 0.0ms preprocess, 466.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 Footnotes, 16 List-items, 1 Page-footer, 1 Page-header, 4 Pictures, 4 Section-headers, 9 Texts, 417.6ms\n",
      "Speed: 0.0ms preprocess, 417.6ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 Footnotes, 24 List-items, 1 Page-header, 4 Pictures, 6 Section-headers, 14 Texts, 388.0ms\n",
      "Speed: 0.0ms preprocess, 388.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 Footnotes, 24 List-items, 2 Pictures, 5 Section-headers, 6 Texts, 467.0ms\n",
      "Speed: 1.8ms preprocess, 467.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Footnote, 28 List-items, 1 Page-footer, 1 Page-header, 4 Section-headers, 433.9ms\n",
      "Speed: 0.0ms preprocess, 433.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 1 Page-footer, 2 Section-headers, 1 Text, 368.0ms\n",
      "Speed: 3.1ms preprocess, 368.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:25<01:29, 12.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 5 Pictures, 1 Section-header, 7 Texts, 1 Title, 501.7ms\n",
      "Speed: 0.0ms preprocess, 501.7ms inference, 13.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 9 List-items, 1 Page-footer, 6 Section-headers, 7 Texts, 434.1ms\n",
      "Speed: 1.0ms preprocess, 434.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 11 List-items, 1 Page-footer, 4 Section-headers, 1 Table, 2 Texts, 416.5ms\n",
      "Speed: 0.0ms preprocess, 416.5ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 3 Footnotes, 7 List-items, 1 Page-footer, 3 Section-headers, 1 Table, 2 Texts, 455.6ms\n",
      "Speed: 0.0ms preprocess, 455.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Footnote, 7 List-items, 1 Page-footer, 2 Section-headers, 1 Table, 2 Texts, 755.9ms\n",
      "Speed: 12.4ms preprocess, 755.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 6 List-items, 1 Page-footer, 6 Section-headers, 2 Tables, 5 Texts, 546.8ms\n",
      "Speed: 2.0ms preprocess, 546.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Footnote, 5 List-items, 1 Page-footer, 3 Section-headers, 2 Tables, 3 Texts, 421.2ms\n",
      "Speed: 0.0ms preprocess, 421.2ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Footnote, 2 List-items, 1 Page-footer, 1 Page-header, 3 Section-headers, 1 Table, 4 Texts, 437.0ms\n",
      "Speed: 0.2ms preprocess, 437.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 5 List-items, 1 Page-footer, 3 Section-headers, 2 Tables, 6 Texts, 417.9ms\n",
      "Speed: 2.9ms preprocess, 417.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 17 List-items, 1 Page-footer, 3 Section-headers, 1 Text, 470.2ms\n",
      "Speed: 2.3ms preprocess, 470.2ms inference, 12.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Caption, 1 Page-footer, 1 Picture, 453.9ms\n",
      "Speed: 1.4ms preprocess, 453.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 Footnotes, 14 List-items, 1 Page-footer, 3 Section-headers, 1 Text, 445.9ms\n",
      "Speed: 0.0ms preprocess, 445.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Caption, 3 List-items, 1 Page-footer, 1 Picture, 1 Section-header, 1 Text, 433.3ms\n",
      "Speed: 0.0ms preprocess, 433.3ms inference, 1.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 List-items, 1 Page-footer, 2 Section-headers, 1 Table, 2 Texts, 438.3ms\n",
      "Speed: 2.0ms preprocess, 438.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 12 List-items, 1 Page-footer, 4 Section-headers, 430.4ms\n",
      "Speed: 0.9ms preprocess, 430.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Page-footer, 2 Section-headers, 6 Texts, 418.6ms\n",
      "Speed: 0.0ms preprocess, 418.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:37<01:14, 12.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 List-item, 1 Picture, 2 Section-headers, 7 Texts, 1 Title, 385.8ms\n",
      "Speed: 0.0ms preprocess, 385.8ms inference, 15.6ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 480x640 1 Caption, 14 List-items, 1 Page-footer, 1 Page-header, 1 Picture, 6 Section-headers, 3 Texts, 396.3ms\n",
      "Speed: 1.2ms preprocess, 396.3ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Caption, 20 List-items, 1 Page-footer, 1 Picture, 4 Section-headers, 404.8ms\n",
      "Speed: 0.0ms preprocess, 404.8ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 Caption, 11 List-items, 1 Page-header, 3 Pictures, 6 Section-headers, 3 Tables, 4 Texts, 434.2ms\n",
      "Speed: 0.0ms preprocess, 434.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 12 List-items, 3 Pictures, 5 Section-headers, 3 Tables, 3 Texts, 413.9ms\n",
      "Speed: 15.7ms preprocess, 413.9ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 20 List-items, 1 Page-footer, 1 Page-header, 3 Section-headers, 1 Table, 1 Text, 400.0ms\n",
      "Speed: 0.0ms preprocess, 400.0ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 30 List-items, 1 Page-footer, 1 Page-header, 4 Section-headers, 1 Table, 2 Texts, 381.2ms\n",
      "Speed: 0.0ms preprocess, 381.2ms inference, 15.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 18 List-items, 1 Page-footer, 1 Page-header, 3 Pictures, 9 Section-headers, 3 Texts, 395.2ms\n",
      "Speed: 0.0ms preprocess, 395.2ms inference, 0.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 640x480 1 Page-footer, 2 Section-headers, 10 Texts, 395.8ms\n",
      "Speed: 0.0ms preprocess, 395.8ms inference, 15.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:46<00:55, 11.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 Captions, 1 Section-header, 7 Tables, 1 Text, 400.3ms\n",
      "Speed: 0.0ms preprocess, 400.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 8 List-items, 2 Section-headers, 1 Table, 1 Text, 1 Title, 519.4ms\n",
      "Speed: 0.0ms preprocess, 519.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 Tables, 25 Texts, 403.7ms\n",
      "Speed: 0.0ms preprocess, 403.7ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:50<00:34,  8.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 Caption, 4 List-items, 1 Page-footer, 2 Section-headers, 6 Tables, 2 Texts, 566.9ms\n",
      "Speed: 0.0ms preprocess, 566.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 6 List-items, 1 Page-footer, 1 Section-header, 1 Table, 6 Texts, 397.2ms\n",
      "Speed: 0.0ms preprocess, 397.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 21 List-items, 1 Section-header, 21 Texts, 480.1ms\n",
      "Speed: 12.3ms preprocess, 480.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 3 List-items, 1 Picture, 1 Section-header, 1 Table, 5 Texts, 437.3ms\n",
      "Speed: 14.9ms preprocess, 437.3ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:56<00:23,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 Caption, 3 List-items, 1 Page-footer, 2 Section-headers, 6 Tables, 1 Text, 440.9ms\n",
      "Speed: 0.0ms preprocess, 440.9ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 7 List-items, 1 Page-footer, 2 Section-headers, 19 Texts, 546.3ms\n",
      "Speed: 2.0ms preprocess, 546.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 List-items, 1 Page-footer, 1 Picture, 1 Section-header, 1 Table, 5 Texts, 493.0ms\n",
      "Speed: 2.0ms preprocess, 493.0ms inference, 0.9ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [01:01<00:13,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 4 Captions, 1 Picture, 6 Tables, 551.1ms\n",
      "Speed: 2.0ms preprocess, 551.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 Captions, 2 Section-headers, 2 Tables, 2 Texts, 674.0ms\n",
      "Speed: 0.0ms preprocess, 674.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 List-items, 1 Section-header, 1 Table, 8 Texts, 475.4ms\n",
      "Speed: 0.0ms preprocess, 475.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 4 Section-headers, 23 Texts, 585.0ms\n",
      "Speed: 2.0ms preprocess, 585.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 3 List-items, 3 Section-headers, 2 Tables, 18 Texts, 535.7ms\n",
      "Speed: 0.0ms preprocess, 535.7ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Page-header, 2 Tables, 1 Text, 453.5ms\n",
      "Speed: 5.1ms preprocess, 453.5ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 List-items, 1 Section-header, 2 Tables, 4 Texts, 473.1ms\n",
      "Speed: 2.0ms preprocess, 473.1ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 List-item, 1 Picture, 2 Section-headers, 7 Texts, 455.1ms\n",
      "Speed: 1.9ms preprocess, 455.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Page-header, 4 Section-headers, 4 Tables, 6 Texts, 468.4ms\n",
      "Speed: 2.3ms preprocess, 468.4ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 2 Captions, 1 Picture, 2 Tables, 6 Texts, 1 Title, 417.5ms\n",
      "Speed: 2.0ms preprocess, 417.5ms inference, 11.2ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 4 Section-headers, 2 Tables, 5 Texts, 511.6ms\n",
      "Speed: 2.0ms preprocess, 511.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [01:10<00:07,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 2 Captions, 3 List-items, 4 Section-headers, 6 Tables, 3 Texts, 1 Title, 434.8ms\n",
      "Speed: 1.0ms preprocess, 434.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 19 List-items, 2 Section-headers, 9 Texts, 579.5ms\n",
      "Speed: 1.0ms preprocess, 579.5ms inference, 0.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Caption, 1 Picture, 1 Table, 4 Texts, 412.2ms\n",
      "Speed: 0.0ms preprocess, 412.2ms inference, 15.5ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [01:14<00:00,  8.25s/it]\n"
     ]
    }
   ],
   "source": [
    "def detect_and_parser(folder_path, model_path='yolov10x_best.pt'):\n",
    "    \n",
    "    model = YOLO(model_path)\n",
    "    pdf_document = fitz.open('./test_source/' + folder_path.split('/')[-1] + '.pdf')\n",
    "    \n",
    "    markdown_document = pymupdf4llm.to_markdown(pdf_document, page_chunks=True)\n",
    "    \n",
    "    image_files = [f for f in os.listdir(folder_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    sorted_image_files = natsorted(image_files, key=get_number_from_filename)\n",
    "      \n",
    "    docs = {} \n",
    "    doc_id = 0\n",
    "    temp = ''\n",
    "    pre_class_name=''\n",
    "    sub_class_name=''\n",
    "    check_order = ''\n",
    "    extracted_text = ''\n",
    "    p_x1, p_y1, p_x2, p_y2 = 0, 0, 0, 0\n",
    "    \n",
    "    for i, image_file in enumerate(sorted_image_files): \n",
    "        markdown = markdown_document[i]\n",
    "        markdown_tables = markdown['text'].split('\\n\\n\\n')\n",
    "        \n",
    "        page = pdf_document[i] \n",
    "        page_width = int(page.rect.width)\n",
    "        page_height = int(page.rect.height)\n",
    "        \n",
    "        image_path = os.path.join(folder_path, image_file) \n",
    "        image = cv2.imread(image_path) \n",
    "        image = cv2.resize(image, (page_width, page_height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "        results = model(source=image, conf=0.2, iou=0.8)[0] \n",
    "        \n",
    "        detections = sv.Detections.from_ultralytics(results) \n",
    "\n",
    "        new_detections = []\n",
    "        for item in detections:\n",
    "            xyxy, mask, confidence, class_id, tracker_id, data = item\n",
    "            new_detections.append(\n",
    "                        {\n",
    "                            'xyxy': xyxy,\n",
    "                            'data': data,\n",
    "                            'class_id': class_id\n",
    "                        }\n",
    "                    )\n",
    "    \n",
    "        sorted_detections_o = transpose_detection(image,new_detections)    \n",
    "        sorted_detections_d = detect_filter(sorted_detections_o)\n",
    "        sorted_detections_w = width_plus(sorted_detections_d)\n",
    "        sorted_detections =  detect_filter_head(sorted_detections_w)\n",
    "        words = page.get_text(\"words\")\n",
    "        \n",
    "        \n",
    "        for i,sorted_detection in enumerate(sorted_detections):\n",
    "            \n",
    "            if i < len(sorted_detections)-1:\n",
    "                sub_class_name = sorted_detections[i+1]['data']['class_name']\n",
    "            if i > 0  :\n",
    "                 pre_class_name = sorted_detections[i-1]['data']['class_name']\n",
    "                 p_x1,p_y1,p_x2,p_y2 = sorted_detections[i-1]['xyxy']\n",
    "\n",
    "            x1, y1, x2, y2 = sorted_detection['xyxy']\n",
    "            \n",
    "            if sorted_detection['data']['class_name'] == 'Section-header' and temp != '' and pre_class_name !='Section-header' and not fitz.Rect(x1, y1, x2, y2).intersects(fitz.Rect(p_x1,p_y1,p_x2,p_y2)) and sub_class_name != 'Picture':\n",
    "                \n",
    "                \n",
    "                \n",
    "                docs[doc_id] = temp.lstrip()\n",
    "                temp = ''\n",
    "                doc_id += 1\n",
    "                 \n",
    "                 \n",
    "            elif sorted_detection['data']['class_name'] == 'Page-footer':\n",
    "                pass\n",
    "                \n",
    "            table_temp = ''\n",
    "             \n",
    "            for w in words: \n",
    "                if fitz.Rect(w[:4]).intersects(fitz.Rect(x1, y1, x2, y2)):\n",
    "                    \n",
    "                    if sorted_detection['data']['class_name'] == 'Table':\n",
    "                        table_temp += w[4]\n",
    "                        \n",
    "                    elif  not fitz.Rect(w[:4]).intersects(fitz.Rect(p_x1,p_y1,p_x2,p_y2)):\n",
    "                        temp += ' ' + w[4]\n",
    "                        \n",
    "            if sorted_detection['data']['class_name'] == 'Table':\n",
    "                \n",
    "                table_text = trans_table(markdown_tables,table_temp)\n",
    "                \n",
    "                pattern = r\"\\(단위: [^)]*\\)\"\n",
    "                match_table = re.search(pattern, table_text)\n",
    "                match_temp = re.search(pattern, temp) \n",
    "                \n",
    "  \n",
    "                if match_temp and match_table:\n",
    "                      table_text = table_text.replace(match_table.group(),'')\n",
    "                \n",
    "                elif match_temp:\n",
    "                      extracted_text = match_temp.group()\n",
    "                    \n",
    "                elif match_table:\n",
    "                      extracted_text = match_table.group()\n",
    "                else:\n",
    "                      table_text = extracted_text + table_text\n",
    "                \n",
    "     \n",
    "                temp += table_text\n",
    "                \n",
    "            temp += '\\n'\n",
    "            \n",
    "    if temp != '':  \n",
    "        \n",
    "        if pre_class_name=='Text' and '집행절차' in temp and sorted_detection['data']['class_name'] == 'Picture':\n",
    "            keyword = \"사업 집행절차\"\n",
    "            index = temp.find(keyword)\n",
    "            check_order = temp[index + len(keyword):]\n",
    "\n",
    "            q = f\"\"\"\n",
    "                            다음 정보를 바탕으로 요구사항에 답하세요:\n",
    "\n",
    "                            {check_order}\n",
    "                            \n",
    "                            요구사항: 절차의 순서를 올바르게 정렬하고 ,로 구분해주세요. \n",
    "\n",
    "                            \n",
    "                            주어진 요구사항만 답변하세요.\n",
    "\n",
    "                            답변:\n",
    "                            \"\"\"\n",
    "\n",
    "            answer = make_answer(q)\n",
    "            temp = temp[:index+ len(keyword)] + ' ' + answer\n",
    "            \n",
    "        docs[doc_id] = temp.lstrip()\n",
    "        if doc_id != 0:\n",
    "            docs[doc_id-1] = docs[doc_id - 1].replace(docs[doc_id], '')\n",
    "    \n",
    "    for i in range(doc_id): \n",
    "        if i > len(docs):\n",
    "            break\n",
    "        \n",
    "        low = len(docs[i])\n",
    "        if low < 232:\n",
    "            docs[i + 1] = docs[i] + docs[i+1]\n",
    "            del docs[i]\n",
    "        \n",
    "      \n",
    "          \n",
    "       \n",
    "    parser_path = './dacon/parser_docs'\n",
    "    if not os.path.exists(parser_path):\n",
    "        os.makedirs(parser_path,exist_ok=True)\n",
    "    with open(f'./dacon/parser_docs/{folder_path.split(\"/\")[-1]}.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(docs, f, ensure_ascii=False, indent=4)\n",
    "        \n",
    "\n",
    "# pdf -> file name\n",
    "pdf_path = './test_source'\n",
    "files = [f.replace('.pdf', '') for f in os.listdir(pdf_path)]\n",
    "for file_name in tqdm(files):\n",
    "        detect_and_parser('./dacon/test_png/'+file_name, model_path='yolov10x_best.pt')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
